{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nTopic Modelling\n===============\nThe following example shows how to generate a topic model from a corpus and then determine the topic of a\nnew document.\n\nNOTE: This is an example to show how to run the procedure however due to the small dataset used\nthe results are likely to be non-sensical.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import enlp.understanding.topics as tp\nimport enlp.processing.stdtools as stdt\nimport spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load example text and get stopwords\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with open(\"example_data/en_nlptexts.txt\", \"r\") as file:\n    text=file.read()\n\nall_stopwords, stopwords_nb, stopwords_en = stdt.get_stopwords()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocess text - for this example we have a very small corpus to allow the documentation\nto build therefore we will split the single document into paragraphs for processing to\nimitate multiple document input and we will also remove stopwords and punctuation  as the text is too small.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Split text into paragraphs to imitate documents\ndocs = text.split('\\n\\n')\n# Remove \\n and replace with space\ndocs = [d.replace('\\n',' ') for d in docs]\n\n# Because example text is small, remove stopwords and punctuation\nen = spacy.load('en_core_web_md')\nstopwords, stops_nb, stops_en = stdt.get_stopwords()\ndocs = [stdt.rm_punctuation(en,stdt.rm_stopwords(en, d, stops_en)) for d in docs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create topic model & visualise keywords per topic\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tp_model, dictionary = tp.bow_topic_modelling(docs,no_topics=3)\n# print topics\ntp.print_topic_words(tp_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Determine the topic of a new document\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fake_doc = 'This is a sentence about the importance of artificial intelligence.'\ndoc_topics = tp.determine_topics(fake_doc, tp_model, dictionary)\n\n# Visualise the top topics for the document\nprint (doc_topics.sort_values(['score']).head())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}