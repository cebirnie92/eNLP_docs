{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nTF-IDF Important Words\n======================\nThe following example compute tf-idf of words in a document to determine the most important words.\n\nNOTE: This is an example to show how to run the procedure however due to the small dataset used\nthe results are likely to be non-sensical.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import enlp.understanding.distributions as dists\nimport enlp.processing.stdtools as stdt\nimport spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load example text\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with open(\"example_data/en_historynlp.txt\", \"r\") as file:\n    text=file.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocess text - for this example we have a very small corpus to allow the documentation\nto build therefore we will split the single document into paragraphs for processing to\nimitate multiple document input and we will also remove stopwords as the text is too small\nfor the tf-idf computation to handle them. For normal procedures you should NOT remove stopwords\nprior to computing tf-idf scores.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Split text into paragraphs to imitate documents\nparagraphs = text.split('\\n\\n')\n# Remove \\n and replace with space\nparagraphs = [p.replace('\\n',' ') for p in paragraphs]\n\n# Because example text is small, remove stopwords as they'll influence tf-idf scores\nen = spacy.load('en_core_web_md')\nstopwords, stops_nb, stops_en = stdt.get_stopwords()\nparagraphs = [stdt.rm_stopwords(en, p, stops_en) for p in paragraphs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute tf-idf scores and determine most important words across full corpus\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores = dists.compute_tfidf(paragraphs)\nprint (dists.important_words_per_corpus(scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Determine most important words per document (or for this example, per paragraph)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "iw_p_d = dists.important_words_per_doc(scores)\n\nfor i, iw in enumerate(iw_p_d):\n    print ('Paragraph %i important words: ' %int(i+1))\n    print (iw)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}