{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nRemoving Stopwords\n==================\nXXX\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import necessary packages\nfrom enlp.processing.stdtools import get_stopwords, rm_stopwords, tokenise\nimport enlp.understanding.distributions as dists\nimport spacy\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nplt.close('all') # very important for read the docs to avoid it crashing due to memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load text to be processed and the appropriate language model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load text file\nwith open(\"example_data/en_historynlp.txt\", \"r\") as file:\n    text=file.read()\nprint (text)\n\n# Load spacy language model\nlangmodel = spacy.load('en_core_web_md')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get stopwords: the stopwords function will get all english and norwegian stopwords\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stopwords_func, stopwords_nb_func, stopwords_en_func = get_stopwords()\nprint (stopwords_en_func[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remove english stopwords\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "processed_text = rm_stopwords(langmodel, text, stopwords_en_func)\nprint (processed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that the stopwords have been removed then the sentences no longer make much sense. Therefore, an alternative to\nviewing the text output is to look at the distribution of the remaining text\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "orig_top10 = pd.DataFrame(dists.freq_dist(tokenise(langmodel, text)), columns=['token', 'count'])\npr_top10 = pd.DataFrame(dists.freq_dist(tokenise(langmodel, processed_text)), columns=['token', 'count'])\n\nprint (\"ORIGINAL - top 10 words\")\nprint (orig_top10.head(10))\nprint (\" \")\nprint (\"PROCESSED - top 10 words\")\nprint (pr_top10.head(10))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}